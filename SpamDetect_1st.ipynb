{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting spam with Perceptrons\n",
    "\n",
    "One of the first and successful applications of AI in the field of cybersecurity is Spam Detection, and one of the most famous is **SpamAssassin**\n",
    "\n",
    "The strategies that can be applied are different, but the most common and simpler one uses **Neural Networks (NNs)**\n",
    "in the most basic way wich is **Perceptrons**"
   ]
  },
  {
   "source": [
    "## NNs at the basics - **the Perceptron**\n",
    "The Perceptron is one the first successful implementations of neuron in the field of **AI**.\n",
    "\n",
    "Just like a neuron of human brain is characterized by a layered structure\n",
    "\n",
    "![neuron of a human brain](./resources/HumanNeuron.jpg)\n",
    "\n",
    "The artificial rapresentation of the neuron implemented thourgh the Perceptron model is structured in a such way to associate a given output value to one or more levels of input data:\n",
    "\n",
    "![AI neuron](./resources/AiNeuron.jpg)\n",
    "\n",
    "The mechanism that transform the input data into an output value is implemented by making use of appropriate weighing of the the values of an input, wich are summarized to an activate function wich, when exceeding a certain threshold,produces a value of output that is forwarded to the remaining components of the neural network.\n",
    "\n",
    "## We have to find the right weight!\n",
    "\n",
    "The difference between the stastical models and AI algorithms is that the algorithms implement an optimization strategy based on iteration, for each iteration, the algo tries to adjust the estimate of the values, giving to them a bigger or lower weight depending on the cost that function that we have to minimize. The scope of the algo is to find an optimal weight to estimate values in order to obtain rielable future predictions on unknown future data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## How a Spam filter works\n",
    "Imagine that we are going to separete our emails by categorizing them based on the presence ro the absence of certain keywords that occurs in our emails witha certain frequency. To do this we can list on table all the incoming emails and after running the AI function giving them a tag to classify them by two paramenters **HAM** or **SPAM**.\n",
    "\n",
    "As we said we are going to count the occurence of certain keywords within the text of the email and we will assign a score to each individual message so we can classify all the incoming emails. \n",
    "\n",
    "We will identify a threshold value that allows us to separate smap messages. If the score exceeds the threshold value, the mail will be classified as SPAM if not as HAM.\n",
    "The threshold  value will be constantly updated to take into account the new series of spam emails that we will receive in future."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Example of Spam Filter\n",
    "First of all let's classify emails based on sospicious keywork. For simplicity let's consider the most rapresentative sospicious keywords, buy and sex.\n",
    "So we are going to create a table where for each email we identifie the occurence of each individual keywords, and after that we indicate if the email is Spam or Ham:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Email|      Buy|      Sex|     Spam or Ham?|\n",
    "|:-------------|:-----------|:------|:------|\n",
    "|1|1|0|H|\n",
    "|2|0|1|H|\n",
    "|3|0|0|H|\n",
    "|4|1|1|S|\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "At this point, we will assign a score to every single email message:\n",
    "The score will be calculated by a function that takes into account the number of accourences of sospicious keywords contained within text.\n",
    "\n",
    "A possible scoring function could be the sum of the occureces of our two keywords, represented in this case by the $B$ variable instead of the world buy, and the $S$ variable instead of the word sex.\n",
    "\n",
    "So the function will be:\n",
    "$$ y = B + S; $$\n",
    "We can also set different weight to rapresent variables of the respective keywords, based on the fact that, for example, the keyword sex contained within the message is indicative of a greater probability of spam than the word buy.\n",
    "\n",
    "It is clear that if both words are present in the text of the email, the probability of it being spam increases. Therefore, we will attribute a lower weight of 2 to the $B$ variable and a greater weight of 3 to the $S$ variable.\n",
    "\n",
    "Our scoring function, corrected with the relative weights assigned to the variables/keyword, therefore becomes the following:\n",
    "\n",
    "$$ y = 2B + 3S; $$\n",
    "Now let's try to reclassify our emails, calculating the relative scores with our scoring function:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "|Email|Buy|Sex|$2B + 3S$|Spam or Ham?|\n",
    "|:-------------|:-----------|:------|:------|:------|\n",
    "|1|1|0|2|H|\n",
    "|2|0|1|3|H|\n",
    "|3|0|0|0|H|\n",
    "|4|1|1|5|S|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "At this point, we must try to identify a threshold value that effectively separates spam from ham. Indeed, a threshold value between 4 and 5 allows us to properly separate the spam from the ham.\n",
    "\n",
    "Let's translate all of this in mathematical formulas, to use it in our algorithms..\n",
    "\n",
    "So our function to determine the score is: \n",
    "\n",
    "$$ y = 2B + 3S $$\n",
    "\n",
    "This identify a straight line in the Cartesian plane, so the classifier used by our spam filter is a **linear classifier**.\n",
    "If we substitute our $B$ and $S$ value with a matrix $X_{i}$ cointaing them, and after introducing a vector $w_{i}$ we can say:\n",
    "\n",
    "$$ y = \\sum w_{i}x_{i} = w_{1}x_{1} + w_{2}x_{2} + \\dot +w_{n}x_{n} $$\n",
    "\n",
    "with index $i$ going from 1 to $n$.\n",
    "\n",
    "This way we have genralized out linead classifier to an unspecified number of variables, $n$, rather than limiting ourselves to just 2 keywords.\n",
    "\n",
    "In fact, our function translates into a sum of products that can easily be representend as a product of matrices and vector:\n",
    "\n",
    "$$ y = wTx $$\n",
    "\n",
    "$wT$ stands for the transported weights carrier, necessary calculating the product of the matrices and vectors.\n",
    "\n",
    "To rapresent the threshold value in formal terms we are gonna say:\n",
    "\n",
    "$$ if, wx> \\theta \\to f(y) = +1$$;\n",
    "\n",
    "$$if, wx< \\theta \\to f(y) = -1 $$\n",
    "\n",
    "That translates to:\n",
    "\n",
    "$$ w_{1}x_{1} + w_{2}x_{2} + ... +w_{n}x_{n} \\geq \\theta \\to y = + 1$$;\n",
    "\n",
    "$$w_{1}x_{1} + w_{2}x_{2} + ... +w_{n}x_{n} < \\theta \\to y = - 1 $$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## How the Perceptron learns\n",
    "The Perceptron learing process can be synthesized in these following steps:\n",
    "* Initializing the weights to a predefined value(usually eaqual to 0)\n",
    "* Calculating the output value, $Y_{i}$, for each corresponding training sample, $X_{i}$\n",
    "* Updating the weights on the basis of the distance between the expected output value(that is, the $Y$ value associated with the original clas label corresponding input data, $X_{i}$)and the predicted value (the ***Yi***, value estimated by the Perceptron)\n",
    "\n",
    "In practice, the individual weights are updated according to the following formola:\n",
    "\n",
    "$$ w_{i} = w_{i} + \\Delta w_{i} $$\n",
    "\n",
    "Here, the $\\Delta w_{i}$ vlaue represents the deviation between the expected ($Y_{i}$)\n",
    "$$\\Delta w_{i} = \\lambda(y- y_{i})x_{i}$$\n",
    "\n",
    "The $\\lambda$ costant rapresent the learing rate assigned to the Perceptron. The $\\lambda$ usually assumes a value between 0.0 and 1.0, a value assigned to the Perceptron in the initial phase.\n",
    "The value of the learing rate **is crucial** for the learing of the Perceptron and so is necessary to carefully evaluate the value to be attribued to the $\\lambda$ costant to omptimize the results returned.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Let's write some code\n",
    "\n",
    "We will use scikit-learn library to create a simple spam filter based on the Perceptron. The dataset is based on the sms spam collection available at: <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\"_blank\">https://archive.ics.uci.edu/ml/datasets/sms+spam+collection</a> \n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      type  sex  buy\n0      ham    0    0\n1      ham    0    0\n2     spam    0    0\n3      ham    0    0\n4      ham    0    0\n...    ...  ...  ...\n5569  spam    0    0\n5570   ham    0    0\n5571   ham    0    0\n5572   ham    0    1\n5573   ham    0    0\n\n[5574 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def count_occurence(string, substring):\n",
    "    return string.count(substring)\n",
    "#importing the collection file into a dataFrame \n",
    "df_first = pd.read_csv('./resources/smsSpamCollection.csv', header=None)\n",
    "#creating a new dataFrame for the Perceptron with the info from the the df_first\n",
    "df = pd.DataFrame(index=df_first.index, columns = ['type','sex','buy'])\n",
    "df['type'] = df_first.iloc[:,0].values\n",
    "#counting the occurence of the word 'sex' for eache message\n",
    "df['sex'] = df_first.iloc[:,1].apply(count_occurence, args = ('sex', ))\n",
    "#counting the occurence of the word 'buy' for eache message\n",
    "df['buy'] = df_first.iloc[:,1].apply(count_occurence, args = ('buy', ))\n",
    "print(df)\n",
    "#exporting the data into a .csv file\n",
    "df.to_csv('./resources/smsSpamPerceptron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}